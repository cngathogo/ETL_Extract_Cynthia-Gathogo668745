{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 12,
>>>>>>> 1e60c74 (Add notebook to existing folder)
   "id": "1e94e15d-491b-4bc2-ac58-559d0261d66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 299\n",
      "Columns: 14\n",
      "\n",
      "Sample data:\n",
      "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
      "0  75.0        0                       582         0                 20   \n",
      "1  55.0        0                      7861         0                 38   \n",
      "2  65.0        0                       146         0                 20   \n",
      "3  50.0        1                       111         0                 20   \n",
      "4  65.0        1                       160         1                 20   \n",
      "\n",
      "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
      "0                    1  265000.00               1.9           130    1   \n",
      "1                    0  263358.03               1.1           136    1   \n",
      "2                    0  162000.00               1.3           129    1   \n",
      "3                    0  210000.00               1.9           137    1   \n",
      "4                    0  327000.00               2.7           116    0   \n",
      "\n",
      "   smoking  time  DEATH_EVENT                   timestamp  \n",
      "0        0     4            1  2025-06-10 21:59:06.728920  \n",
      "1        0     6            1  2025-06-10 21:59:06.728920  \n",
      "2        1     7            1  2025-06-10 21:59:06.728920  \n",
      "3        0     7            1  2025-06-10 21:59:06.728920  \n",
      "4        0     8            1  2025-06-10 21:59:06.728920  \n",
      "\n",
      "Extracted 299 rows fully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
<<<<<<< HEAD
    "# Load dataset\n",
    "df = pd.read_csv(\"custom_data.csv.zip\")\n",
=======
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"custom_data_with_timestamp.csv.zip\")\n",
>>>>>>> 1e60c74 (Add notebook to existing folder)
    "\n",
    "# Displaying basic stats\n",
    "print(\"Rows:\", df.shape[0])\n",
    "print(\"Columns:\", df.shape[1])\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Success message\n",
    "print(f\"\\nExtracted {df.shape[0]} rows fully.\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 8,
   "id": "5559f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring the right directory is used\n",
    "import os\n",
    "os.chdir(\"C:/Users/Cynth/OneDrive/Desktop/ETL_Extract_CynthiaGathogo_668745\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> 1e60c74 (Add notebook to existing folder)
   "id": "a383fb26-e7f3-404b-be5c-1be32e38ec69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "['.gitignore', '.ipynb_checkpoints', 'custom_data.csv.zip', 'etl_extract.ipynb', 'last_extraction.txt', 'README.md', 'Untitled.ipynb']\n"
=======
      "['.git', '.gitignore', 'custom_data_with_timestamp.csv.zip', 'etl_extract.ipynb', 'last_extraction.txt', 'README.md', 'screenshots']\n"
>>>>>>> 1e60c74 (Add notebook to existing folder)
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import os\n",
    "print(os.listdir())\n",
    "\n"
=======
    "#Confirming that all folders are there\n",
    "import os\n",
    "print(os.listdir())\n"
>>>>>>> 1e60c74 (Add notebook to existing folder)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9992e314-78a7-44c2-af0e-e738b77d38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"last_extraction.txt\", \"w\") as f:\n",
    "    f.write(\"2024-06-01 12:00:00\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 10,
>>>>>>> 1e60c74 (Add notebook to existing folder)
   "id": "8e9a1e2a",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "KeyError",
     "evalue": "'updated_at'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Cynth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'updated_at'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     last_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert column to datetime\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mupdated_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Filter new or updated records\u001b[39;00m\n\u001b[0;32m     15\u001b[0m new_data \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m last_time]\n",
      "File \u001b[1;32mc:\\Users\\Cynth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Cynth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'updated_at'"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 0 rows incrementally since last check.\n"
>>>>>>> 1e60c74 (Add notebook to existing folder)
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load full dataset\n",
<<<<<<< HEAD
    "df = pd.read_csv(\"custom_data.csv.zip\")  \n",
=======
    "df = pd.read_csv(\"custom_data_with_timestamp.csv.zip\")  \n",
>>>>>>> 1e60c74 (Add notebook to existing folder)
    "\n",
    "# Read last extraction time\n",
    "with open(\"last_extraction.txt\", \"r\") as f:\n",
    "    last_time = datetime.strptime(f.read().strip(), \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Convert column to datetime\n",
<<<<<<< HEAD
    "df['updated_at'] = pd.to_datetime(df['updated_at']) \n",
    "\n",
    "# Filter new or updated records\n",
    "new_data = df[df['updated_at'] > last_time]\n",
=======
    "df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "\n",
    "# Filter new or updated records\n",
    "new_data = df[df['timestamp'] > last_time]\n",
>>>>>>> 1e60c74 (Add notebook to existing folder)
    "\n",
    "# Print result\n",
    "print(f\"Extracted {new_data.shape[0]} rows incrementally since last check.\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 11,
>>>>>>> 1e60c74 (Add notebook to existing folder)
   "id": "9e304839",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"last_extraction.txt\", \"w\") as f:\n",
    "    f.write(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE \"transformed_full.csv\"\n",
    "import pandas as pd\n",
    "df= pd.read_csv(\"custom_data_with_timestamp.csv.zip\")\n",
    "\n",
    "#Applying transformations\n",
    "def transform(df):\n",
    "    df=df.drop_duplicates() #cleaning\n",
    "    df= df.dropna(0) #fills rows with missing values with zero(cleaning)\n",
    "    df['risk_score']= df['serum_creatinine'] * df['age']/df['ejection_fraction'] #enrichment\n",
    "    \n",
    "    df['timestamp']=pd.to_datetime(df['timestamp']) #repeated for clarity purposes.(Structural transformation)\n",
    "    df= df .drop(columns=['smoking'])#Filtering\n",
    "#Categorization\n",
    "bins=[0,30,45,60,75,100]\n",
    "labels=['<30','30-45','45-60','60-75','75+']\n",
    "df['age_group']=pd.cut(df['age'], bins=bins, labels=labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e42fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the 'transformed_incremental.csv'\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"custom_data_with_timestamp.csv.zip\")\n",
    "df['timestamp']=pd.to_datetime(df['timestamp'])\n",
    "cutoff= pd.to_datetime(\"2025-06-01\")\n",
    "df_incremental= df[df['timestamp']> cutoff]"
   ]
>>>>>>> 1e60c74 (Add notebook to existing folder)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
